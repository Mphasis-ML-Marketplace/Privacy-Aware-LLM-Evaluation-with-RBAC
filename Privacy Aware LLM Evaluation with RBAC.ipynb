{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Privacy Aware LLM Evaluation with RBAC\n",
    "\n",
    "This solution Evaluate privacy awareness with RBAC for an LLM based chatbot such that responses to information seeking queries respect access controls.\n",
    "\n",
    "\n",
    "This sample notebook shows you how to do assessment of LLM based chatbot system.\n",
    "\n",
    "> **Note**: This is a reference notebook and it cannot run unless you make changes suggested in the notebook.\n",
    "\n",
    "#### Pre-requisites:\n",
    "1. **Note**: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**\n",
    "1. Some hands-on experience using [Amazon SageMaker](https://aws.amazon.com/sagemaker/).\n",
    "1. To use this algorithm successfully, ensure that:\n",
    "    1. Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used: \n",
    "        1. **aws-marketplace:ViewSubscriptions**\n",
    "        1. **aws-marketplace:Unsubscribe**\n",
    "        1. **aws-marketplace:Subscribe**  \n",
    "    2. or your AWS account has a subscription to Vector Search for Company Description. \n",
    "\n",
    "#### Contents:\n",
    "1. [Subscribe to the algorithm](#1.-Subscribe-to-the-algorithm)\n",
    "1. [Prepare dataset](#2.-Prepare-dataset)\n",
    "\t1. [Dataset format expected by the algorithm](#A.-Dataset-format-expected-by-the-algorithm)\n",
    "\t1. [Configure the dataset](#B.-Configure-the-dataset)\n",
    "\t1. [Upload datasets to Amazon S3](#C.-Upload-datasets-to-Amazon-S3)\n",
    "1. [Generate Data and Questions for Assessment](#3:-Generate-Data-and-Questions-for-Assessment)\n",
    "\t1. [Set up environment](#3.1-Set-up-environment)\n",
    "\t1. [Run Training](#3.2-Run-Training)\n",
    "1. [Deploy Endpoint and Provide Assessment Results](#4:-Deploy-Endpoint-and-Provide-Assessment-Results)\n",
    "    1. [Deploy Assessment Pipeline](#A.-Deploy-Assessment-Pipeline)\n",
    "    1. [Create input payload](#B.-Create-input-payload)\n",
    "    1. [Perform real-time inference](#C.-Perform-real-time-inference)\n",
    "    1. [Visualize output](#D.-Visualize-output)\n",
    "    1. [Delete the endpoint](#E.-Delete-the-endpoint)\n",
    "1. [Clean-up](#5.-Clean-up)\n",
    "\t1. [Unsubscribe to the listing (optional)](#A.-Unsubscribe-to-the-listing-(optional))\n",
    "\n",
    "\n",
    "#### Usage instructions\n",
    "You can run this notebook one cell at a time (By using Shift+Enter for running a cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Subscribe to the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To subscribe to the algorithm:\n",
    "1. Open the algorithm listing page **Privacy Aware LLM Evaluation with RBAC**\n",
    "1. On the AWS Marketplace listing,  click on **Continue to subscribe** button.\n",
    "1. On the **Subscribe to this software** page, review and click on **\"Accept Offer\"** if you agree with EULA, pricing, and support terms. \n",
    "1. Once you click on **Continue to configuration button** and then choose a **region**, you will see a **Product Arn**. This is the algorithm ARN that you need to specify while training a custom ML model. Copy the ARN corresponding to your region and specify the same in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_arn ='privacy-awareness-copy-3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json \n",
    "import uuid\n",
    "from sagemaker import ModelPackage\n",
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "from urllib.parse import urlparse\n",
    "import boto3\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Dataset format expected by the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm requires data in the format as described for best results:\n",
    "* The solution need three files application_info.json, credential.json, table_data.csv.\n",
    "* The application_info.json contains the information about the chatbot and differnt role who can use it.\n",
    "* credential.json contains credentials to access the claude model on aws bedrock.\n",
    "* table_data.csv contain schema of tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Configure the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset='input/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Upload datasets to Amazon S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sage.Session()\n",
    "bucket=sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training input location\n",
    "common_prefix = \"privacy-awareness\"  \n",
    "training_input_prefix = common_prefix + \"/training-input-data\"\n",
    "TRAINING_WORKDIR = \"input\"\n",
    "training_input = sagemaker_session.upload_data(TRAINING_WORKDIR, key_prefix=training_input_prefix)\n",
    "print(\"Training input uploaded to \" + training_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Generate Data and Questions for Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the input dataset is available in an accessible Amazon S3 bucket, we are ready to generate the synthetic data and questions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_location = 's3://{}/privacy-awareness/{}'.format(bucket, 'output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Run Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For information on creating an `Estimator` object, see [documentation](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please select an appropriate instance type based on the training requirement, here training refers to the generation of data and questions for assessment.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_type='ml.m5.4xlarge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-02 10:00:20 Starting - Starting the training job...\n",
      "2024-07-02 10:00:45 Starting - Preparing the instances for trainingProfilerReport-1719914419: InProgress\n",
      "...\n",
      "2024-07-02 10:01:16 Downloading - Downloading the training image\n",
      "2024-07-02 10:01:16 Training - Training image download completed. Training in progress..\u001b[34mStarting the train function.\u001b[0m\n",
      "\u001b[34mGenerated data and questions saved..\u001b[0m\n",
      "\u001b[34mSuccess\u001b[0m\n",
      "\n",
      "2024-07-02 10:07:50 Uploading - Uploading generated training model\n",
      "2024-07-02 10:07:50 Completed - Training job completed\n",
      "Training seconds: 409\n",
      "Billable seconds: 409\n"
     ]
    }
   ],
   "source": [
    "#Create an estimator object for running a training job\n",
    "estimator = sage.algorithm.AlgorithmEstimator(\n",
    "    algorithm_arn=algo_arn,\n",
    "    base_job_name=\"privacy-awareness-training\",\n",
    "    role=role,\n",
    "    input_mode=\"File\",\n",
    "    output_path=output_location,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    instance_count=1,\n",
    "    instance_type=instance_type\n",
    ")\n",
    "#Run the training job.\n",
    "estimator.fit({\"training\": training_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See this [blog-post](https://aws.amazon.com/blogs/machine-learning/easily-monitor-and-visualize-metrics-while-training-models-on-amazon-sagemaker/) for more information how to visualize metrics during the process. You can also open the training job from [Amazon SageMaker console](https://console.aws.amazon.com/sagemaker/home?#/jobs/) and monitor the metrics/logs in **Monitor** section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training output data downloaded.\n"
     ]
    }
   ],
   "source": [
    "# training output location\n",
    "common_prefix = \"privacy-awareness\"  \n",
    "training_output_prefix = estimator.model_data.split(sep=bucket)[1][1:] # gives the prefix of training output zipped file\n",
    "TRAINING_OUTPUT_WORKDIR = \"output\"\n",
    "training_output = sagemaker_session.download_data(TRAINING_OUTPUT_WORKDIR, bucket=bucket, key_prefix=training_output_prefix)\n",
    "print(\"Training output data downloaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = tarfile.open(\"output/model.tar.gz\")\n",
    "file.extractall('output/')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated data and questions are saved in output folder. Please give your chatbot the generated data (generated_data.xlsx) as context and give answers for the given questions in questions.csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4: Deploy Endpoint and Provide Assessment Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can deploy the inference endpoint for performing assessment of the chatbot based on answers provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='privacy-awareness'\n",
    "\n",
    "content_type='text/csv'\n",
    "\n",
    "real_time_inference_instance_type='ml.m5.large'\n",
    "batch_transform_inference_instance_type='ml.m5.large'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Deploy Assessment Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      "-----!"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import csv_serializer\n",
    "predictor = estimator.deploy(1, real_time_inference_instance_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once endpoint is created, you can perform real-time inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Create input payload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The assessment pipeline accepts csv file containing questions generated in training pipeline and its answers in specific format.  \n",
    "For detailed instructions, please refer input details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'inference_input/test_data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Perform real-time inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_name = 'inference_output/output.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"ContentType\": \"text/csv; charset=utf-8\",\r\n",
      "    \"InvokedProductionVariant\": \"AllTraffic\"\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!aws sagemaker-runtime invoke-endpoint \\\n",
    "    --endpoint-name $predictor.endpoint_name \\\n",
    "    --body fileb://$file_name \\\n",
    "    --content-type $content_type \\\n",
    "    --region $sagemaker_session.boto_region_name \\\n",
    "    $output_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D. Visualize output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('inference_output/output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doctor</th>\n",
       "      <th>Nurse</th>\n",
       "      <th>Administrative Staff</th>\n",
       "      <th>Patient</th>\n",
       "      <th>Administrator</th>\n",
       "      <th>overall_performace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aware</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Over Aware</th>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Under Aware</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Doctor     Nurse  Administrative Staff   Patient  \\\n",
       "Aware        0.300000  0.466667              0.566667  0.450000   \n",
       "Over Aware   0.366667  0.233333              0.216667  0.233333   \n",
       "Under Aware  0.333333  0.300000              0.216667  0.316667   \n",
       "\n",
       "             Administrator  overall_performace  \n",
       "Aware             0.516667                0.46  \n",
       "Over Aware        0.250000                0.26  \n",
       "Under Aware       0.233333                0.28  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.set_index(pd.Index(['Aware', 'Over Aware', 'Under Aware']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assess the privacy awareness of LLM, awareness, over-awareness, and under-awareness percentage is given\n",
    "- Awareness percentage: percentage of questions for which model given desired answer\n",
    "- Over-awareness percentage: percentage of questions for which model should give answer but it refused\n",
    "- Under-awareness percentage: percentage of questions for which model should not give answer but it gives\n",
    "- Under-awareness percentage also signify about in how frequently model can do privacy leakage\n",
    "- These percentages also provides role spacific perfermace of the chatbot system\n",
    "\n",
    "- The awareness percentage signifies the chatbots' adherence to the role based access control."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E. Delete the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have successfully performed a real-time inference, you do not need the endpoint any more. you can terminate the same to avoid being charged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Unsubscribe to the listing (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to unsubscribe to the algorithm, follow these steps. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model. \n",
    "\n",
    "**Steps to unsubscribe to product from AWS Marketplace**:\n",
    "1. Navigate to __Machine Learning__ tab on [__Your Software subscriptions page__](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=mlmp_gitdemo_indust)\n",
    "2. Locate the listing that you want to cancel the subscription for, and then choose __Cancel Subscription__  to cancel the subscription.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
